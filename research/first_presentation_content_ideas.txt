# Presentation
## Introduction
Code Expert is a Cloud-based IDE which executes the code of the users in containers. There are two ways to allow users to flexibly set up their execution environment. The first way which is the currently used in CodeExpert is to provide a preconfigured monolithic container with all possible dependencies. The second way, which is explored in my Bachelor Thesis, is to set up the image at runtime to the needs of the user. 
The current solution is fast once the image has been build but there are tradeoffs:

## Problem of current solution and motivation of new approach
Currently, a lecturer can choose one of several pre-baked OS images to set up the coding environment for the students. If this does not suit his needs and he wants to add a new package or change the version of some existing library, then this has to be done manually from a CX-team member. This process is time intensive since every new package creates a new exciting way things can break and might not even be available to install on the RedHat distribution. It has become a large burden to maintain these ever growing images.

Ideally each lecturer should be able to use any language and install any package with minimal fuss.

The goal is to build the image based on the needs of the lecturer. The advantages are:
- Lecturer gets more responsibility and flexibility
- Lecturer can quickly iterate over and test different configuration
- (Ideally one) Lean base image is maintained and updated.
- Preconfigured extensions of this base image for common environments like python, C++, Java etc. to make it easier for lecturer which don't need to customise much. 

## Nix
The main challenge for building images at runtime based on the user configuration is that the time to build the image must be fast that the user experience is not impacted by building this container. 

To solve this challenge I've come across Nix which is declarative, reproducible OS package manager. Due to Nix's design its package store is highly cacheable and allows for building environments in a composable way. Using the Nix programming language the user can specify the dependencies for his repl and Nix will build the environment. Nix is great fit, as it allows for building environments in a composable way (taking minimal base image, adding the programming language and libraries and then putting the packages needed by the user on top) without having to maintain large docker images.   

Nix is a purely functional package manager (packages don't have side-effects) and Nix stores the packages in the *Nix store*. 

Packages are build from Nix expressions, which is a simple functional language. A Nix expression describes everything that goes into a package build action (a “derivation”): other packages, sources, the build script, environment variables for the build script, etc. Nix tries very hard to ensure that Nix expressions are deterministic: building a Nix expression twice should yield the same result.

[TODO leave this out or make the context clearer]
A quick analogy with programming languages: you have the heap with all the objects, that corresponds to the Nix store. You have objects that point to other objects, those correspond to derivations.

With Nix it is easy to support variants of a package (call nix expression as a function with different arguments) and they don't conflict with each other in the Nix store.

Nix has content addressable store which handles conflicts even with many versions of the same package. Package management operations always add new versions in different paths and are therefore atomic. This means old versions are still there after an upgrade and you can roll back. 

## Approaches
I've found 2 feasible approaches to solve this challenge.
I'll outline the high-level workflow from start to finish for both approaches and talk about the challenges of each. 
### Approach 1
Don't build image at runtime if config changes.

Assume we start with 
- Container from minimal image is running and has the Nix package manager installed. A local.nix is available in this container to let the user extend the environment with additional packages.

To run a script the user calls nix-shell. The nix-shell evaluates the local.nix file and downloads the dependencies from a binary cache and builds them. The packages are stored in the Nix store as paths to derivations. 

Downloading and building is only done by the nix-shell if the config changes and the package is not already in the store available.

After that the nix-shell sets environment variables to correct derivation paths in the store such that the binaries can be found by the compiler. 

Now we are done and the environment with all dependencies is ready.

You may observe that if one user downloads the dependencies then another does not have them available in the nix/store, since container have non-persistent storage. The solution is to mount a shared disk image with the Nix store in it into every container. Nix's content addressable store make this conflict free even with many versions of the same package

Now a shared store could be problematic for security reasons but Nix has multi-user support to make the sharing of the nix store possible. 

#### Further performance evaluations
The downloading and building of the packages can take a long time. The solution is to use a seeded nix store which is prebuilt with the most used packages downloaded. [Adding a package then becomes as simple as adding a dependency in the local.nix file.]

The evaluation of the local.nix and the exporting the environment variables by the nix-shell can take small delay.
The solution is to persist the environment variables between restarts of the nix-shell and invalidate the cache if the configuration changes.

### Approach 2
Build a new container at runtime every time the config changes.

For this approach I've looked at two different directions. The first using Nix in so called *builder container* to build a new image. The second is to use a tool called *Nixery* to build a new image. 

Nixery builds ad-hoc images based on the package names and serves these images from a private registry. The problem is that Nixery is a tool which doesn't allow to specify the packages in a nix expression. The result is less flexibility, which is exactly what we don't want. Therefore I won't pursue this direction.

The flow of the first direction looks as follows:
Assume we start with 
- Container from minimal image is running and has the Nix package manager installed. A local.nix is available in this container to let the user extend the environment with additional packages.
- Additionally, we assume that one *builder container* is running the background. 

The next step is to run the builder with the local.nix expression. The builder then builds the image using the Nix package manager. (Nix can build Docker images very efficiently)
After that the result of the builder needs to be loaded into docker and then we can start the container. This concludes the flow and the environment is ready.

#### Performance evaluations
We can avoid unnecessary builds by only building a new image if the configuration (local.nix) changes. For example by computing the hash over the configuration file or more sophisticated methods. 

To make this approach scale and enable simultaneous builds we can run multiple builder container in parallel. Each builder uses a persistent Nix store shared among the builders. This is similar to approach one where the repl container have a shared nix-store whereas in this approach each builder container has a shared store. 

## Conclusion
Give recommendation on which approach to favor and why

Goal: Make a decision based on numbers (measurements).


## Next steps
Continue working on both approaches such that I can compare both approaches with each other and to the current approach.

Prototypes for both approaches to make the use cases clear. The prototypes should consist of a predefined base image and some language specific examples and then I can go through the build flow and repeadiatly simulate the actions of the user.

In the next step I want to take measurements on the two uses cases of starting the container after a config change and don't change the configuration. The most important metric will be the time until the container is ready. Later on I'll do simulations to determine the disk space usage, the number of layers used and the CPU performance to determine the right hardware in the Cloud for the two approaches.
It would also be beneficial to gather measurements and come up with optimisations if we consider i.e. that 100 people all build container at the same time or if the libraries the user wants to install are huge in terms of space (i.e. pytorch or large C++ gui library). 
   
## Schedule
see ipad notes